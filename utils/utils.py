import numpy as np
import scipy.sparse as sp


def encode_onehot(labels):
    classes = set(labels)
    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in enumerate(classes)}
    labels_onehot = np.array(list(map(classes_dict.get, labels)), dtype=np.int32)
    return labels_onehot

def adj_to_bias(adj, sizes, nhood=1):
    mt = np.eye(sizes)
    for _ in range(nhood):
       mt = np.matmul(mt, (adj + np.eye(sizes)))
    return mt#-1e9 * (1.0 - mt)

sample = ".sample"

#def load_data(path="./data/malware_backup/", dataset="malware", cuda = False):
def load_data(path="./data/malware/", dataset="malware", cuda = False):
    """Load citation network dataset (cora only for now)"""
    print('Loading {} dataset...'.format(dataset))

    idx_features_labels = np.genfromtxt("{}{}.content".format(path, dataset), dtype=np.dtype(str))
    #features = sp.csr_matrix(idx_features_labels[:, 1:], dtype=np.float32)
    #features = normalize_features(features).todense()
    labels = encode_onehot(idx_features_labels[:, 0])
    features = labels

    # build graph
    valid_adj = np.array([sp.csr_matrix(i) for i in np.load("{}{}.valid.graphs{}.npy".format(path, dataset, sample))])
    valid_graph_labels = encode_onehot(np.load("{}{}.valid.labels{}.npy".format(path, dataset, sample)).astype(np.float32))
    train_adj = np.array([sp.csr_matrix(i) for i in np.load("{}{}.train.graphs{}.npy".format(path, dataset,sample))])
    train_graph_labels = encode_onehot(np.load("{}{}.train.labels{}.npy".format(path, dataset,sample)).astype(np.float32))
    valid_adj = np.array([adj_to_bias(adj, features.shape[0]) for adj in valid_adj])
    train_adj = np.array([adj_to_bias(adj, features.shape[0]) for adj in train_adj])
    #train_adj = np.array([adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj) for adj in train_adj])
    #valid_adj = np.array([adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj) for adj in valid_adj])
    #train_adj = np.array([normalize_adj(adj + sp.eye(adj.shape[0])).todense() for adj in train_adj])
    #valid_adj = np.array([normalize_adj(adj + sp.eye(adj.shape[0])).todense() for adj in valid_adj])
    #print( features)
    #print( labels)
    #print( valid_adj)
    #print( valid_graph_labels)
    #print( train_adj)
    #print( train_graph_labels)
    return features, labels, valid_adj, valid_graph_labels, train_adj, train_graph_labels


def normalize_adj(mx):
    """Row-normalize sparse matrix"""
    rowsum = np.array(mx.sum(1))
    r_inv_sqrt = np.power(rowsum, -0.5).flatten()
    r_inv_sqrt[np.isinf(r_inv_sqrt)] = 0.
    r_mat_inv_sqrt = sp.diags(r_inv_sqrt)
    return mx.dot(r_mat_inv_sqrt).transpose().dot(r_mat_inv_sqrt)


def normalize_features(mx):
    """Row-normalize sparse matrix"""
    rowsum = np.array(mx.sum(1))
    r_inv = np.power(rowsum, -1).flatten()
    r_inv[np.isinf(r_inv)] = 0.
    r_mat_inv = sp.diags(r_inv)
    mx = r_mat_inv.dot(mx)
    return mx


def accuracy(output, labels):
    preds = output.max(1)[1].type_as(labels)
    correct = preds.eq(labels).double()
    correct = correct.sum()
    return correct / len(labels)

