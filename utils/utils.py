import numpy as np
import scipy.sparse as sp
from sklearn.metrics import roc_curve, auc, accuracy_score,recall_score,precision_score

def encode_onehot(labels):
    classes = set(labels)
    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in enumerate(classes)}
    labels_onehot = np.array(list(map(classes_dict.get, labels)), dtype=np.int32)
    return labels_onehot

def adj_to_bias(adj, sizes, nhood=1):
    mt = np.eye(sizes)
    for _ in range(nhood):
       mt = np.matmul(mt, (adj + np.eye(sizes)))
    return mt#-1e9 * (1.0 - mt)

import json
def load_voc(filename):
    try:
        with open(filename, 'rb') as f:
            data = f.read()
            data = json.loads(data.decode())
            return [value for key, value in data.items()]
    except:
            exit()

from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import LabelEncoder

def calOnehot(ranges):
    label_encoder = LabelEncoder()
    integer_encoded = label_encoder.fit_transform(ranges)
    onehot_encoder = OneHotEncoder(sparse=False)
    onehot_encoded = onehot_encoder.fit_transform(integer_encoded.reshape(len(integer_encoded), 1))
    return onehot_encoder, onehot_encoded

sample = ""

def load_butian_data(path="./data_windows/malware/", dataset="malware", cuda = True):
    labels_encoder, labels = calOnehot(load_voc("{}{}.json".format(path,'voc')))
    features = labels
    valid_adj = np.array([sp.csr_matrix(i) for i in np.load("{}{}.valid.graphs{}.npy".format(path, dataset, sample))])
    valid_graph = np.load("{}{}.valid.labels{}.npy".format(path, dataset, sample))
    valid_graph_name = valid_graph[:,0]
    valid_graph_labels = valid_graph[:,1]
    encoder, valid_graph_labels = calOnehot(valid_graph_labels.astype(np.float32))

    train_adj = np.array([sp.csr_matrix(i) for i in np.load("{}{}.train.graphs{}.npy".format(path, dataset,sample))])
    train_graph = np.load("{}{}.train.labels{}.npy".format(path, dataset, sample))
    train_graph_name = train_graph[:,0]
    train_graph_labels = train_graph[:,1]
    train_graph_labels = encoder.transform(train_graph_labels.astype(np.float32).reshape(-1,1))
    test_adj = np.array([sp.csr_matrix(i) for i in np.load("{}{}.test.graphs{}.npy".format(path, dataset,sample))])
    test_graph = np.load("{}{}.test.labels{}.npy".format(path, dataset, sample))
    test_graph_name = test_graph[:,0]
    test_graph_labels = test_graph[:,1]
    test_graph_labels = encoder.transform(test_graph_labels.astype(np.float32).reshape(-1,1))

    if cuda:
       valid_adj = np.array([adj_to_bias(adj, features.shape[0]) for adj in valid_adj])
       train_adj = np.array([adj_to_bias(adj, features.shape[0]) for adj in train_adj])
       test_adj = np.array([adj_to_bias(adj, features.shape[0]) for adj in test_adj])
    else:
       valid_adj = np.array([adj.todense() for adj in valid_adj])
       train_adj = np.array([adj.todense() for adj in train_adj])
       test_adj = np.array([adj.todense() for adj in test_adj])
    return features, labels, valid_adj, valid_graph_labels, valid_graph_name, train_adj, train_graph_labels, train_graph_name, test_adj, test_graph_name

def load_data(path="./data_windows/malware/", dataset="malware", cuda = True):
    """Load citation network dataset (cora only for now)"""
    print('Loading {} dataset...'.format(dataset))

    #idx_features_labels = np.genfromtxt("{}{}.content".format(path, dataset), dtype=np.dtype(str))
    #features = sp.csr_matrix(idx_features_labels[:, 1:], dtype=np.float32)
    #features = normalize_features(features).todense()
    #labels = encode_onehot(idx_features_labels[:, 0])
    labels_encoder, labels = calOnehot(load_voc("{}{}.json".format(path,'voc')))
    features = labels

    # build graph
    print("{}{}.valid.graphs{}.npy".format(path, dataset, sample))
    valid_adj = np.array([sp.csr_matrix(i) for i in np.load("{}{}.valid.graphs{}.npy".format(path, dataset, sample))])
    encoder, _ = calOnehot([0,1])
    valid_graph_labels = encoder.transform(np.load("{}{}.valid.labels{}.npy".format(path, dataset, sample)).astype(np.float32).reshape(-1,1))
    train_adj = np.array([sp.csr_matrix(i) for i in np.load("{}{}.train.graphs{}.npy".format(path, dataset,sample))])
    train_graph_labels = encoder.transform(np.load("{}{}.train.labels{}.npy".format(path, dataset,sample)).astype(np.float32).reshape(-1,1))
    if cuda:
       valid_adj = np.array([adj_to_bias(adj, features.shape[0]) for adj in valid_adj])
       train_adj = np.array([adj_to_bias(adj, features.shape[0]) for adj in train_adj])
    else:
       valid_adj = np.array([adj.todense() for adj in valid_adj])
       train_adj = np.array([adj.todense() for adj in train_adj])
    #train_adj = np.array([adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj) for adj in train_adj])
    #valid_adj = np.array([adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj) for adj in valid_adj])
    #train_adj = np.array([normalize_adj(adj + sp.eye(adj.shape[0])).todense() for adj in train_adj])
    #valid_adj = np.array([normalize_adj(adj + sp.eye(adj.shape[0])).todense() for adj in valid_adj])
    return features, labels, valid_adj, valid_graph_labels, train_adj, train_graph_labels


def normalize_adj(mx):
    """Row-normalize sparse matrix"""
    rowsum = np.array(mx.sum(1))
    r_inv_sqrt = np.power(rowsum, -0.5).flatten()
    r_inv_sqrt[np.isinf(r_inv_sqrt)] = 0.
    r_mat_inv_sqrt = sp.diags(r_inv_sqrt)
    return mx.dot(r_mat_inv_sqrt).transpose().dot(r_mat_inv_sqrt)


def normalize_features(mx):
    """Row-normalize sparse matrix"""
    rowsum = np.array(mx.sum(1))
    r_inv = np.power(rowsum, -1).flatten()
    r_inv[np.isinf(r_inv)] = 0.
    r_mat_inv = sp.diags(r_inv)
    mx = r_mat_inv.dot(mx)
    return mx


def accuracy(output, labels):
    preds = output.max(1)[1].type_as(labels)
    correct = preds.eq(labels).double()
    correct = correct.sum()
    return correct / len(labels)

def cal_roc(prediction, all_labels):
       fpr = dict()
       tpr = dict()
       roc_auc = dict()
       #print(prediction.shape,all_labels.shape)
       for i in range(2):
           fpr[i], tpr[i], _ = roc_curve(all_labels[:, i], prediction[:, i])
           roc_auc[i] = auc(fpr[i],tpr[i])
       #fpr['macro'], tpr['macro'] = roc_curve(all_labels[:,0:2], prediction)
       fpr['micro'], tpr['micro'],_ = roc_curve(all_labels[:,0:2].ravel(), prediction.ravel())
       roc_auc['micro'] = auc(fpr['micro'], tpr['micro'])
       print(roc_auc)
       return fpr, tpr, roc_auc
       #savefig([[fpr,tpr,roc_auc]])

def savefig(data, cn = 1):
     import matplotlib
     matplotlib.use('Agg')
     import matplotlib.pyplot as plt
     plt.rcParams['savefig.dpi'] = 600
     plt.rcParams['figure.dpi'] = 600
     plt.clf()
     colors = ["cornflowerblue","lightslategrey","crimson","rebeccapurple","teal","olive","maroon","chocolate","darkseagreen"]
     for color, d in zip(colors, data):
         fpr,tpr,auc,label = d[0],d[1],d[2],d[3]
         plt.plot(fpr[cn], tpr[cn], color = color, label=(label+"(area=%0.2f)") % auc[cn])
     plt.legend(loc="lower right")
     plt.xlabel('False Positive Rate')
     plt.ylabel('True Positive Rate')
     plt.savefig('roc'+str(cn)+'.jpg', dpi=600)
