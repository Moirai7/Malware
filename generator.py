
#!/usr/bin/env python
# -*- coding: utf-8 -*-
import math

import numpy as np
import tensorflow as tf
import tensorflow.contrib.seq2seq as seq2seq

from tensorflow.python.ops.rnn_cell import GRUCell
from tensorflow.python.ops.rnn_cell import LSTMCell
from tensorflow.python.ops.rnn_cell import MultiRNNCell
from tensorflow.python.ops.rnn_cell import DropoutWrapper, ResidualWrapper

from tensorflow.python.ops import array_ops
from tensorflow.python.ops import control_flow_ops
from tensorflow.python.framework import constant_op
from tensorflow.python.framework import dtypes
from tensorflow.python.layers.core import Dense
from tensorflow.python.util import nest

from tensorflow.contrib.seq2seq.python.ops import attention_wrapper
from tensorflow.contrib.seq2seq.python.ops import beam_search_decoder
import data.util as utils
import data.data_utils as data_utils
from helper import *
from detector import Detector, define

class Seq2SeqModel(object):

    def __init__(self, sess, config, mwlist, mode):

        assert mode.lower() in ['train', 'decode', 'pretrain']

        self.config = config
        self.mode = mode.lower()
        self.mwlist = mwlist
        self.sess = sess
        self.detector_config = define()
        self.detector = Detector(self.detector_config, self.mode)        
        self.detector.restore(self.sess, self.detector_config['save_path'])

        self.cell_type = config['cell_type']
        #self.hidden_units = config['hidden_units']
        self.depth = config['depth']
        self.attention_type = config['attention_type']
        self.dtype = tf.float16 if config['use_fp16'] else tf.float32
        #self.bidirectional = config.bidirectional
        self.voc = utils.load_voc(config['source_vocabulary'])
        self.num_symbols = len(self.voc)
        self.total_num = config['batch_size']
        self.hidden_units = len(self.voc)
        self.max_seq_length = config['max_seq_length']
        self.embeddings = tf.get_variable(initializer=tf.one_hot(self.voc, len(self.voc), dtype=self.dtype), name='emmbedding', trainable=False)
        #self.embeddings = tf.one_hot(self.voc, len(self.voc), dtype=self.dtype)
       	self.tau = config['init_temp']#tf.Variable(config['init_temp'], trainable=config['learn_temp'], name='temperature', dtype = self.dtype)

        self.use_residual = config['use_residual']
        self.attn_input_feeding = config['attn_input_feeding']
        self.use_dropout = config['use_dropout']
        self.keep_prob = 1.0 - config['dropout_rate']

        self.optimizer = config['optimizer']
        self.learning_rate = config['learning_rate']
        self.max_gradient_norm = config['max_gradient_norm']
        self.global_step = tf.Variable(0, trainable=False, name='global_step')
        self.global_epoch_step = tf.Variable(0, trainable=False, name='global_epoch_step')
        self.global_epoch_step_op = \
	    tf.assign(self.global_epoch_step, self.global_epoch_step+1)

        self.keep_prob_placeholder = tf.placeholder(self.dtype, shape=[], name='keep_prob')

        self.use_beamsearch_decode=False 
        if self.mode == 'decode':
            self.beam_width = config['beam_width']
            self.use_beamsearch_decode = True if self.beam_width > 1 else False
            self.max_decode_step = config['max_decode_step']
 
        self.build_model()

    def build_model(self):
        print("building model..")

        # Building encoder and decoder networks
        self.init_placeholders()
        self.build_encoder()
        self.build_decoder()

        # Merge all the training summaries
        self.summary_op = tf.summary.merge_all()


    def init_placeholders(self):       
        # encoder_inputs: [batch_size, max_time_steps]
        self.encoder_inputs = tf.placeholder(dtype=tf.int32,
            shape=(None, None), name='encoder_inputs')

        # encoder_inputs_length: [batch_size]
        self.encoder_inputs_length = tf.placeholder(
            dtype=tf.int32, shape=(None,), name='encoder_inputs_length')


        self.total_shape = tf.placeholder(dtype=tf.int32, shape=(None), name='total_shape')
        #self.total_num = self.total_shape[-1]
        self.batch_size = tf.shape(self.encoder_inputs)[0]


    def build_encoder(self):
        print("building encoder..")
        with tf.variable_scope('encoder'):
            self.encoder_cell = self.build_encoder_cell()
            self.encoder_inputs_embedded = tf.nn.embedding_lookup(
                params=self.embeddings, ids=self.encoder_inputs)
            self.encoder_outputs, self.encoder_last_state = tf.nn.dynamic_rnn(
                cell=self.encoder_cell, inputs=self.encoder_inputs_embedded,
                sequence_length=self.encoder_inputs_length, dtype=self.dtype,
                time_major=False)


    def build_decoder(self):
        print("building decoder and attention..")
        with tf.variable_scope('decoder'):
            self.decoder_cell, self.decoder_initial_state = self.build_decoder_cell()

            output_layer = Dense(self.num_symbols, name='output_projection')
            start_tokens = tf.ones([self.batch_size,], tf.int32) * data_utils.start_token
            end_token = data_utils.end_token
            
            helper = GumbelSoftmaxEmbeddingHelper(embedding=self.embeddings, start_tokens=start_tokens,end_token= end_token, tau=self.tau)
            
            max_decoder_length = tf.reduce_max(self.encoder_inputs_length)
            decoder = tf.contrib.seq2seq.BasicDecoder(cell=self.decoder_cell, helper=helper, initial_state=self.decoder_initial_state)#, output_layer=output_layer)
            (self.decoder_outputs_train, self.decoder_last_state_train, self.decoder_outputs_length_train) = (seq2seq.dynamic_decode(decoder=decoder, maximum_iterations=max_decoder_length,impute_finished=True))
            self.decoder_logits_train = tf.identity(self.decoder_outputs_train.rnn_output)
            self.decoder_pred_decode = tf.argmax(self.decoder_outputs_train.sample_id, axis=-1, output_type=tf.int32)
            
            #newinput = data_utils.insertSequence(self.decoder_logits_train, self.encoder_inputs_embedded, self.detector)
            #newintput = data_utils.insertSequence(self.decoder_pred_decode.eval(), self.encoder_inputs.eval(),1, self.total_num)
            '''
            _loss = 0
            for i in range(self.detector.batch_size):
                source, source_len = data_utils.prepare_batch(newintput[i:i*self.detector.batch_size], self.detector.stride, self.detector.maxlen, self.detector.batch_size)
                _, logits = self.detector.predict(self.sess, source, source_len)
                _loss += logits[0] - logits[1]
            '''
            self.accuracy = tf.reduce_mean(tf.cast(tf.equal(self.encoder_inputs, self.decoder_pred_decode), self.dtype))
            masks = tf.sequence_mask(lengths=self.encoder_inputs_length, maxlen=max_decoder_length, dtype=self.dtype, name='masks')
            self.loss = seq2seq.sequence_loss(logits=self.decoder_logits_train, targets=self.encoder_inputs, weights=masks)
            #self.loss = _loss + np.sum(self.decoder_pred_decode**masks**2)/np.sum(masks)/2
            tf.summary.scalar('loss', self.loss)
            self.init_optimizer()
            
    def build_single_cell(self):
        cell_type = LSTMCell
        if (self.cell_type.lower() == 'gru'):
            cell_type = GRUCell
        cell = cell_type(self.hidden_units)

        if self.use_dropout:
            cell = DropoutWrapper(cell, dtype=self.dtype,
                                  output_keep_prob=self.keep_prob_placeholder,)
        if self.use_residual:
            cell = ResidualWrapper(cell)
            
        return cell


    # Building encoder cell
    def build_encoder_cell (self):

        return MultiRNNCell([self.build_single_cell() for i in range(self.depth)])

    def build_decoder_cell_without_att(self):
        encoder_outputs = self.encoder_outputs
        encoder_last_state = self.encoder_last_state
        encoder_inputs_length = self.encoder_inputs_length
        cells = self.build_encoder_cell()
        initial_state = [state for state in encoder_last_state]
        decoder_initial_state = tuple(initial_state)

        return cells, decoder_initial_state

    # Building decoder cell and attention. Also returns decoder_initial_state
    def build_decoder_cell(self):

        encoder_outputs = self.encoder_outputs
        encoder_last_state = self.encoder_last_state
        encoder_inputs_length = self.encoder_inputs_length

        if self.use_beamsearch_decode:
            print ("use beamsearch decoding..")
            encoder_outputs = seq2seq.tile_batch(
                self.encoder_outputs, multiplier=self.beam_width)
            encoder_last_state = nest.map_structure(
                lambda s: seq2seq.tile_batch(s, self.beam_width), self.encoder_last_state)
            encoder_inputs_length = seq2seq.tile_batch(
                self.encoder_inputs_length, multiplier=self.beam_width)

        # Building attention mechanism: Default Bahdanau
        # 'Bahdanau' style attention: https://arxiv.org/abs/1409.0473
        self.attention_mechanism = attention_wrapper.BahdanauAttention(
            num_units=self.hidden_units, memory=encoder_outputs,
            memory_sequence_length=encoder_inputs_length,) 
        # 'Luong' style attention: https://arxiv.org/abs/1508.04025
        if self.attention_type.lower() == 'luong':
            self.attention_mechanism = attention_wrapper.LuongAttention(
                num_units=self.hidden_units, memory=encoder_outputs, 
                memory_sequence_length=encoder_inputs_length,)
 
        # Building decoder_cell
        self.decoder_cell_list = [
            self.build_single_cell() for i in range(self.depth)]
        decoder_initial_state = encoder_last_state

        def attn_decoder_input_fn(inputs, attention):
            if not self.attn_input_feeding:
                return inputs

            # Essential when use_residual=True
            _input_layer = Dense(self.hidden_units, dtype=self.dtype,
                                 name='attn_input_feeding')
            return _input_layer(array_ops.concat([inputs, attention], -1))

        # AttentionWrapper wraps RNNCell with the attention_mechanism
        # Note: We implement Attention mechanism only on the top decoder layer
        self.decoder_cell_list[-1] = attention_wrapper.AttentionWrapper(
            cell=self.decoder_cell_list[-1],
            attention_mechanism=self.attention_mechanism,
            attention_layer_size=self.hidden_units,
            cell_input_fn=attn_decoder_input_fn,
            initial_cell_state=encoder_last_state[-1],
            alignment_history=False,
            name='Attention_Wrapper')

        batch_size = self.batch_size if not self.use_beamsearch_decode \
                     else self.batch_size * self.beam_width
        initial_state = [state for state in encoder_last_state]

        initial_state[-1] = self.decoder_cell_list[-1].zero_state(
          batch_size=batch_size, dtype=self.dtype)
        decoder_initial_state = tuple(initial_state)

        return MultiRNNCell(self.decoder_cell_list), decoder_initial_state


    def init_optimizer(self):
        print("setting optimizer..")
        # Gradients and SGD update operation for training the model
        trainable_params = tf.trainable_variables()
        if self.optimizer.lower() == 'adadelta':
            self.opt = tf.train.AdadeltaOptimizer(learning_rate=self.learning_rate)
        elif self.optimizer.lower() == 'adam':
            self.opt = tf.train.AdamOptimizer(learning_rate=self.learning_rate)
        elif self.optimizer.lower() == 'rmsprop':
            self.opt = tf.train.RMSPropOptimizer(learning_rate=self.learning_rate)
        else:
            self.opt = tf.train.GradientDescentOptimizer(learning_rate=self.learning_rate)

        # Compute gradients of loss w.r.t. all trainable variables
        gradients = tf.gradients(self.loss, trainable_params)

        # Clip gradients by a given maximum_gradient_norm
        clip_gradients, _ = tf.clip_by_global_norm(gradients, self.max_gradient_norm)

        # Update the model
        self.updates = self.opt.apply_gradients(
            zip(clip_gradients, trainable_params), global_step=self.global_step)

    def save(self, sess, path, var_list=None, global_step=None):
        # var_list = None returns the list of all saveable variables
        saver = tf.train.Saver(var_list)

        # temporary code
        #del tf.get_collection_ref('LAYER_NAME_UIDS')[0]
        save_path = saver.save(sess, save_path=path, global_step=global_step)
        print('model saved at %s' % save_path)
        

    def restore(self, sess, path, var_list=None):
        # var_list = None returns the list of all saveable variables
        saver = tf.train.Saver(var_list)
        saver.restore(sess, save_path=path)
        print('model restored from %s' % path)


    def pretrain(self, sess, encoder_inputs, encoder_inputs_length):
        # Check if the model is 'training' mode
        if self.mode.lower() != 'pretrain':
            raise ValueError("train step can only be operated in train mode")

        input_feed = self.check_feeds(encoder_inputs, encoder_inputs_length)
        # Input feeds for dropout
        input_feed[self.keep_prob_placeholder.name] = self.keep_prob
        
        output_feed = [self.updates,	# Update Op that does optimization
                       self.loss,	# Loss for current batch
                       self.decoder_logits_train,self.decoder_pred_decode,self.encoder_inputs,self.encoder_inputs_length, self.accuracy,
                       self.summary_op]	# Training summary
        
        outputs = sess.run(output_feed, input_feed)
        return outputs 	# loss, summary


    def eval(self, sess, encoder_inputs, encoder_inputs_length):
        input_feed = self.check_feeds(encoder_inputs, encoder_inputs_length)
        # Input feeds for dropout

        output_feed = [self.loss,	# Loss for current batch
                       self.decoder_logits_train, self.decoder_pred_decode, self.encoder_inputs, self.encoder_inputs_length, self.accuracy,
                       self.summary_op]	# Training summary
        outputs = sess.run(output_feed, input_feed)
        return outputs	# loss


    def predict(self, sess, encoder_inputs, encoder_inputs_length):
        
        input_feed = self.check_feeds(encoder_inputs, encoder_inputs_length)

        # Input feeds for dropout
 
        output_feed = [self.decoder_pred_decode]
        outputs = sess.run(output_feed, input_feed)

				# GreedyDecoder: [batch_size, max_time_step]
        return outputs[0]	# BeamSearchDecoder: [batch_size, max_time_step, beam_width]


    def check_feeds(self, encoder_inputs, encoder_inputs_length):
        seqs = []
        total_num = 0
        total_shape = []
        for bag in encoder_inputs:
            total_shape.append(total_num)
            total_num += len(bag)
            for seq in bag:
                seqs.append(seq)
        total_shape.append(total_num)
        input_feed = {}
        input_feed[self.total_shape.name] = np.array(total_shape)
        input_feed[self.encoder_inputs.name] = np.array(seqs)
        input_feed[self.encoder_inputs_length.name] = encoder_inputs_length
        input_feed[self.keep_prob_placeholder.name] = 1.0

        return input_feed 

