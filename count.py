import os

from data.data_iterator import TextIterator

def define():
    config = {}
    config['input'] = 'data/train.seq'
    config['valid'] = 'data/valid.seq'
    config['batch_size'] = 1
    config['source_vocabulary'] = 'data/voc.json'
    config['maxlen']=600
    config['stride']=300
    config['max_batch']=900
    return config

config = define()

def count(file_dir):
    f = open(file_dir,'r')
    cnt_1 = 0
    cnt_0 = 0
    while True:
        mystr = f.readline()
        #print('mystr', mystr)
        if not mystr:
            break
        mylist = mystr.split()
        # print(mylist[-1])
        if mylist[-1] == '1':
            cnt_1 = cnt_1 + 1
        if mylist[-1] == '0':
            cnt_0 = cnt_0 + 1
    print('cnt_1',cnt_1)
    print('cnt_0',cnt_0)
    
    '''
    train_set = TextIterator(source=config['input'],
                            batch_size=config['batch_size'],
                            source_dict=config['source_vocabulary'])
    for idx, sources in enumerate(train_set):
        source_seq = sources[0]
        label = sources[1]
        sources, labels = prepare_batch(source_seq, label,max_batch=config['max_batch'], maxlen=config['maxlen'],stride = config['stride'],batch_size=config['batch_size'])
        for source,label in zip(sources, labels):
            if label == '1':
               cnt_1 = cnt_1+1
            elif 
    '''
    

if __name__ == '__main__':
    count('data/train.seq')
    count('data/valid.seq')